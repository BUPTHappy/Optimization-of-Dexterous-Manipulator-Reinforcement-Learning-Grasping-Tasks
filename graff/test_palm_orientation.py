"""
æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯å¦å­¦ä¼šäº†è™å£æœä¸ŠæŠ“å–
"""
import os
import numpy as np
import torch
from a2c_ppo_acktr.envs import make_vec_envs
from a2c_ppo_acktr.utils import get_vec_normalize
import time

def test_palm_orientation(model_path, num_episodes=10):
    """
    æµ‹è¯•æ¨¡å‹çš„è™å£æœä¸ŠæŠ“å–èƒ½åŠ›
    """
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        return
    
    # åŠ è½½æ¨¡å‹
    try:
        actor_critic, ob_rms = torch.load(model_path, map_location='cpu')
        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # è®¾ç½®ç¯å¢ƒå‚æ•°
    grasp_attrs_dict = {
        'dataset': 'contactdb',
        'obj': 'pan',
        'policy': 'cnn-mlp',
        'cnn_arch': 'custom',
        'noise': False,  # æµ‹è¯•æ—¶ä¸åŠ å™ªå£°
        'inputs': ['proprio', 'loc', 'rgb', 'depth', 'aff'],
        'cameras': ['egocentric'],
        'img_res': 128,
        'rewards': {'grasp': 1, 'aff': 1, 'palm_orientation': 0.3},
        'reward_dst_thr': 0.5,
        'obj_mass': 1,
        'obj_rot': True,
        'obj_tr': False,
        'gravity': 9.8,
        'debug': False
    }
    
    # åˆ›å»ºç¯å¢ƒ
    device = torch.device('cpu')
    envs = make_vec_envs('graff-v0', 1, 1, None, None, device, 0, True, 
                        dataset='contactdb', object='pan', 
                        grasp_attrs_dict=grasp_attrs_dict)
    
    # æ¢å¤è§‚å¯Ÿå½’ä¸€åŒ–
    vec_norm = get_vec_normalize(envs)
    if vec_norm is not None:
        vec_norm.eval()
        vec_norm.ob_rms = ob_rms
    
    actor_critic.eval()
    
    # æµ‹è¯•ç»Ÿè®¡
    total_episodes = 0
    successful_grasps = 0
    successful_lifts = 0
    palm_orientation_scores = []
    episode_rewards = []
    
    print(f"\nå¼€å§‹æµ‹è¯• {num_episodes} ä¸ªepisodes...")
    print("=" * 60)
    
    for episode in range(num_episodes):
        obs = envs.reset()
        episode_reward = 0
        episode_palm_scores = []
        episode_grasp = False
        episode_lift = False
        
        print(f"\nEpisode {episode + 1}/{num_episodes}")
        
        for step in range(200):  # æœ€å¤§200æ­¥
            with torch.no_grad():
                _, action, _, _ = actor_critic.act(obs, None, None, deterministic=True)
            
            obs, reward, done, infos = envs.step(action)
            episode_reward += reward.item()
            
            # è·å–ç¯å¢ƒä¿¡æ¯
            if len(infos) > 0 and 'obj_grab' in infos[0]:
                if infos[0]['obj_grab']:
                    episode_grasp = True
                if infos[0]['obj_lift']:
                    episode_lift = True
            
            # è®¡ç®—è™å£æœä¸Šå¾—åˆ†ï¼ˆéœ€è¦è®¿é—®ç¯å¢ƒå†…éƒ¨ï¼‰
            try:
                env = envs.venv.envs[0].env  # è·å–åŸå§‹ç¯å¢ƒ
                while hasattr(env, 'env'):
                    env = env.env
                palm_score = env.get_palm_orientation_reward()
                episode_palm_scores.append(palm_score)
            except:
                pass
            
            if done:
                break
        
        total_episodes += 1
        if episode_grasp:
            successful_grasps += 1
        if episode_lift:
            successful_lifts += 1
        
        episode_rewards.append(episode_reward)
        if episode_palm_scores:
            avg_palm_score = np.mean(episode_palm_scores)
            palm_orientation_scores.append(avg_palm_score)
            print(f"  å¥–åŠ±: {episode_reward:.2f}, æŠ“å–: {'âœ“' if episode_grasp else 'âœ—'}, "
                  f"ä¸¾èµ·: {'âœ“' if episode_lift else 'âœ—'}, è™å£æœä¸Šå¾—åˆ†: {avg_palm_score:.3f}")
        else:
            print(f"  å¥–åŠ±: {episode_reward:.2f}, æŠ“å–: {'âœ“' if episode_grasp else 'âœ—'}, "
                  f"ä¸¾èµ·: {'âœ“' if episode_lift else 'âœ—'}")
    
    # æ‰“å°æµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"æ€»episodes: {total_episodes}")
    print(f"æˆåŠŸæŠ“å–ç‡: {successful_grasps}/{total_episodes} ({100*successful_grasps/total_episodes:.1f}%)")
    print(f"æˆåŠŸä¸¾èµ·ç‡: {successful_lifts}/{total_episodes} ({100*successful_lifts/total_episodes:.1f}%)")
    print(f"å¹³å‡å¥–åŠ±: {np.mean(episode_rewards):.2f} Â± {np.std(episode_rewards):.2f}")
    
    if palm_orientation_scores:
        avg_palm_score = np.mean(palm_orientation_scores)
        print(f"å¹³å‡è™å£æœä¸Šå¾—åˆ†: {avg_palm_score:.3f} Â± {np.std(palm_orientation_scores):.3f}")
        print(f"è™å£æœä¸Šè¡¨ç°: {'ä¼˜ç§€' if avg_palm_score > 0.8 else 'è‰¯å¥½' if avg_palm_score > 0.6 else 'ä¸€èˆ¬' if avg_palm_score > 0.4 else 'è¾ƒå·®'}")
    
    # è¯„ä¼°å»ºè®®
    print("\nè¯„ä¼°å»ºè®®:")
    if successful_grasps == 0:
        print("âŒ æ¨¡å‹è¿˜æ²¡æœ‰å­¦ä¼šæŠ“å–ï¼Œéœ€è¦ç»§ç»­è®­ç»ƒ")
    elif successful_grasps < total_episodes * 0.3:
        print("âš ï¸  æ¨¡å‹å¶å°”èƒ½æŠ“å–ï¼Œä½†æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒ")
    elif successful_grasps < total_episodes * 0.7:
        print("âœ… æ¨¡å‹å·²ç»å­¦ä¼šåŸºæœ¬æŠ“å–ï¼Œå¯ä»¥è€ƒè™‘è°ƒæ•´å¥–åŠ±æƒé‡ä¼˜åŒ–è™å£æœä¸Š")
    else:
        print("ğŸ‰ æ¨¡å‹æŠ“å–èƒ½åŠ›å¾ˆå¥½ï¼")
    
    if palm_orientation_scores and avg_palm_score < 0.5:
        print("ğŸ“ è™å£æœä¸Šçº¦æŸè¿˜éœ€è¦åŠ å¼ºï¼Œå»ºè®®å¢åŠ palm_orientationå¥–åŠ±æƒé‡")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', type=str, default='./expts/graff_palm_seed1/models/best.pt',
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--episodes', type=int, default=10,
                       help='æµ‹è¯•episodesæ•°é‡')
    args = parser.parse_args()
    
    test_palm_orientation(args.model, args.episodes)
